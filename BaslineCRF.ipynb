{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Conditional Random Fields for Surface Segmentation Demo 18/08/2020\n",
    "## Tumi Moeng"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Cleaning\n",
    "First, the data we received needs to be cleaned and the surface segmentation\n",
    " forms need to be generated to be used by the models. To this end I created a\n",
    " class called 'DataCleaner' which takes the data we received and filters out\n",
    " that which we need from that which we dont need and generates some more data\n",
    " that we need.<br>\n",
    " This class takes the data in the following form:<br>\n",
    " ngezinkonzo&emsp;khonzo&emsp;P&emsp;[RelConc]-nga[NPre]-i[NPrePre]-zin[BPre]-konzo[NStem]<br>\n",
    " And converts it to the following form:<br>\n",
    " ngezinkonzo | nge-zin-konzo | nga[NPre]i[NPrePre]zin[BPre]konzo[NStem]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from morphology.DataCleaner import DataCleaner\n",
    "languages = [\"zulu\", \"swati\", \"ndebele\", \"xhosa\"]\n",
    "\n",
    "for lang in languages:\n",
    "    print(\"Language: \" + lang)\n",
    "    inputFile = DataCleaner(lang + \".train.conll\")\n",
    "    inputFile.reformat(lang + \".clean.train\")\n",
    "    inputFile = DataCleaner(lang + \".test.conll\")\n",
    "    inputFile.reformat(lang + \".clean.test\")\n",
    "    print(lang + \" cleaning complete.\\n#############################################\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparation for Hyper-parameter Optimisation\n",
    "Secondly, in preparation for the hyper-parameter optimisation that we will need to do\n",
    " to ensure our models are as good as possible we needed to be able to develop a test /\n",
    " validation set to be used in the optimisation process. To this end, I created a class\n",
    " called 'ValidationSetCreation' that extracts about 10% of the data from the training set\n",
    " and puts it into a validation set. This 10% represents roughly the same amount of entries\n",
    " as the test set contains."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from morphology.ValidationSetCreation import ValidationSet\n",
    "\n",
    "for lang in languages:\n",
    "    print(\"Language: \" + lang)\n",
    "    file_name = lang + \".clean.train.conll\"\n",
    "    # print(file_name)\n",
    "    inputFile = ValidationSet(file_name)\n",
    "    file_name = lang + \".clean.dev.conll\"\n",
    "    # print(file_name)\n",
    "    inputFile.create_validation_set(file_name)\n",
    "    print(lang + \" validation set complete.\\n#############################################\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conditional Random Field using SKLearn_CRFSuite\n",
    "Finally, we are now able to train the CRF using the data we have developed and\n",
    "train the CRF on this data. We give it input as the string of the language it\n",
    "is to be trained on and it will give 2 outputs. The first is a list of lists of\n",
    "what the CRF predicted the labels will be for the words in the test set. The second\n",
    " is a list of lists of what the actual labels for the word in the test set are. Both\n",
    " inner lists of labels occur in the following form:<br>\n",
    " For the word 'komthombo' which segments to 'ko-m-thombo the inner list would be\n",
    " [B,E,S,B,M,M,M,M,E] where:<br>\n",
    " B = Beginning of Segment<br>\n",
    " M = Middle of Segment<br>\n",
    " E = End of Segment<br>\n",
    " S = Single Length Segment<br>\n",
    " The results method which takes in the list of predicted answers and actual answers\n",
    " can be used to print to console the results of the CRF such as the <b>precision</b>,\n",
    " <b>recall</b> and <b>F1-Score</b>."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from BaselineCRF import BaselineCRF\n",
    "crf = BaselineCRF(\"zulu\")\n",
    "predicted_ans, actual_ans = crf.surface_segmentation()\n",
    "print(\"First Value of Predicted Answer List: \"+predicted_ans[0])\n",
    "print(\"First Value of Actual Answer List: \"+actual_ans[0])\n",
    "crf.results(predicted_ans, actual_ans)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}